<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lu1hoao.github.io</id>
    <title>Lu Ying • Posts by &#34;memory&#34; tag</title>
    <link href="https://lu1hoao.github.io" />
    <updated>2022-05-29T14:23:28.000Z</updated>
    <category term="C" />
    <category term="combination" />
    <category term="permutation" />
    <category term="程式新手" />
    <category term="Visual studio 2022" />
    <category term="sort" />
    <category term="VS Code" />
    <category term="WSL" />
    <category term="debug" />
    <category term="OS" />
    <category term="scheduling" />
    <category term="Memory" />
    <category term="Disk" />
    <category term="Synchronization" />
    <category term="Deadlock" />
    <entry>
        <id>https://lu1hoao.github.io/2022/05/29/os/os-12/</id>
        <title>Virtual Memory (下)</title>
        <link rel="alternate" href="https://lu1hoao.github.io/2022/05/29/os/os-12/"/>
        <content type="html">&lt;h3 id=&#34;概要&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#概要&#34;&gt;#&lt;/a&gt; 概要&lt;/h3&gt;
&lt;p&gt;本篇文是 virtual memory 的最後一篇 (終於) 主要說明 Allocation of Frame 的不同方法以及這隻中會遇到的問題，並提及 Memory-Mapped Files 的概念&lt;/p&gt;
&lt;h3 id=&#34;allocation-of-frames&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#allocation-of-frames&#34;&gt;#&lt;/a&gt; Allocation of Frames&lt;/h3&gt;
&lt;p&gt;在分配 frame 的理論中有一種稱為 &lt;strong&gt;Fixed Allocation&lt;/strong&gt; ，即該 process 在執行之前就已經知道自己可以拿到幾個 frame ，fixed allocation 又可以分為 &lt;strong&gt;equal allocation&lt;/strong&gt; 和 &lt;strong&gt;prpportional allocation&lt;/strong&gt; 前者是每個 process 都拿到相同數目的 frame ，後者是根據 process 大小調整分配到的 frame 數目，另外系統通常會保留一些 free frame 在 free frame buffer pool，以備不時之需。&lt;br /&gt;
除了 Fixed Allocation 還有一種稱為 &lt;strong&gt;Prioroity Allociation&lt;/strong&gt; ，當優先權較高的 process frame 不夠時，可以拿取低優先權 process 的 frame ，又稱為 Global replacement ，這樣做會讓程式每次執行的時間都不太一樣，低優先權程式可能跑好久才跑完，但產率較高。&lt;br /&gt;
在具有 non-uniform memory access 的系統中，則發展出 lgroups 的概念，把鄰近的 CPU 和 memory 組成群組，群組內可使用自己的排成和 paging 演算法，稱為 &lt;strong&gt;low latency groups&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;trashing&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#trashing&#34;&gt;#&lt;/a&gt; Trashing&lt;/h3&gt;
&lt;p&gt;a process is busy swapping pages in and out 就稱為 Trashing，Trashing 的主因是因為太多 process 在 memory 中，造成每個 process 分到的 page frame 很少，產生很多 page fault，然而當這種情況發生時 CPU 的使用率會非常低，作業系統發現 CPU 使用率低又派發更多 process 導致不斷的惡性循環，我們以下方流程說明&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;page fault to get page&lt;/li&gt;
&lt;li&gt;replace existing frame&lt;/li&gt;
&lt;li&gt;but quickly need replaced frame block&lt;/li&gt;
&lt;li&gt;another process added to the system&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那 trashing 最常發生在甚麼時候呢？我們前面說過 demand paging 最重要的觀念就是執行時，放需要的程式碼進來就好，不會互相影響的區段放在 disk 也沒關係，假設現在有一個 process 由三個大迴圈組成，那 trashing 最容易發生在迴圈交界處，從第一個迴圈要跑到第二個迴圈時，所需的資料量橫跨第一個迴圈所屬的 page 和第二個迴圈所屬的 page 因此容易造成 page fault 。&lt;/p&gt;
&lt;h3 id=&#34;working-set-model&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#working-set-model&#34;&gt;#&lt;/a&gt; Working-set Model&lt;/h3&gt;
&lt;p&gt;我們使用 Working-set Model 來監看 trashing 是否會發生，核心概念是這樣：先訂出一段時間範圍，稱為 working set window ，看看在這段時間內有幾個 page 被 reference ，假設有 7 個，但所給予的 page frame 只有 4 個，那就容易造成 trashing。&lt;br /&gt;
在做實驗的時候我們又是如何判斷這個 page 有沒有被 reference 呢？假設 working set window 是 10000 ns ，我給與每個 page 10 個 bit ，每一千秒的時候檢查一次，如果這個 page 被 reference 那就把對應到的 bit 設為 1 ，(比如四千秒時，編號 7 被 reference ，那編號 7 的第 4 個 bit 即為 1)，結束後，若該 page 有超過 5 個 bit 為 1 那我們就說該 page 在 working sets 裡面。&lt;br /&gt;
然而使用 working sets 來監測 trashing 有點麻煩，所以實務上會使用 &lt;strong&gt;Page-Fault Frequency&lt;/strong&gt; 的概念，系統會設定一個 page fault 上限，若現在產生的 page fault 遠高於這個上限，那就趕快增加 page frame 給 process ，直到達到一個可以接受的範圍&lt;/p&gt;
&lt;h3 id=&#34;memory-mapped-file&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#memory-mapped-file&#34;&gt;#&lt;/a&gt; Memory Mapped File&lt;/h3&gt;
&lt;p&gt;memory mapped file I/O 是把 disk 中的 page 放到 memory 中，之後若對這個文件有甚麼更動，就相對於在記憶體中做更動，速度會快很多，在做更動之中也不需要立刻把解果從 memory 寫回 disk 中，關掉時在一次儲存就可以了，不過值得注意的是，在 mapping 到 memory 的過程中，是存放在 kernel 的 address space ，所以是耗掉 kernel 的記憶體。&lt;/p&gt;
&lt;h3 id=&#34;slab-allocator&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#slab-allocator&#34;&gt;#&lt;/a&gt; Slab Allocator&lt;/h3&gt;
&lt;p&gt;許多處理器架構上，系統每次分配記憶體都以 page 為單位，但系統執行時大部分資料結構都很小，為一個小物件分配一個 page 會造成很多 internel fragmentation ，所以 Linux 中使用 slab ，slab 把 page 切割成小塊在零售出去，而 cache 則是多個 slab ，kernel 的物件會存放在 cache 裡頭，我們以下圖理解&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/rS1DpQB.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;一個 pgae 被切成 4 個 slab ，每一個 cache 含有 8 個 slab 而 kenel object 就存放在 cache 中。&lt;/p&gt;
&lt;p&gt;以上就是 virtual memory 的最終章，祝大家閱讀愉快&lt;/p&gt;
</content>
        <category term="OS" />
        <category term="Memory" />
        <updated>2022-05-29T14:23:28.000Z</updated>
    </entry>
    <entry>
        <id>https://lu1hoao.github.io/2022/05/29/os/os-11/</id>
        <title>Virtual Memory (中)</title>
        <link rel="alternate" href="https://lu1hoao.github.io/2022/05/29/os/os-11/"/>
        <content type="html">&lt;h3 id=&#34;概要&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#概要&#34;&gt;#&lt;/a&gt; 概要&lt;/h3&gt;
&lt;p&gt;本篇文章主要講述 Page Replacement Policy 探討不同 replacement 的演算法有怎麼樣的差異，又是如何借助一些硬體輔助來實現。&lt;/p&gt;
&lt;h3 id=&#34;page-replacement&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#page-replacement&#34;&gt;#&lt;/a&gt; Page Replacement&lt;/h3&gt;
&lt;p&gt;當 CPU 所需的 page 不在 memory 中，而 memory 中也沒有屬於該 process 的 free frame ，就必須把其中一個不需要的 page 清掉，換需要的 page 進來。舉例來說假設每個 process 都有 3 個 frame 可以用，現在 A process 的 3 個 frame 分別裝了編號 7、 5、 4  的 page ，而需要編號 2 的 page ，那就必須清空 7、5、4 中的其中一個，把編號 2 搬進來，流程如下&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;找到所需 page 在 disk 中的位置 (這裡為編號 2 的 page)&lt;/li&gt;
&lt;li&gt;尋找 free frame&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;若記憶體中本來就有 free frame 那就直接使用&lt;/li&gt;
&lt;li&gt;若記憶體中沒有 free frame ，那就選一個受害者，把它清掉。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;把需要的 page 搬進來&lt;/li&gt;
&lt;li&gt;繼續執行&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;當所需的 page 不在記憶體中即產生 page fault。沒有 free frame 而必須把現有的 page 清掉，這個過程也必須考慮該 page 內容有沒有被修改過，如果有，我們必須先把他的新內容儲存到 disk 中再清掉，如果沒有，直接把待用的 page 覆蓋上去就可以了，為了記錄是否被修改過，在 page table 中的每一項 (即每一個 page) 都有一個 &lt;strong&gt;modify bit&lt;/strong&gt; 。&lt;br /&gt;
至於該選哪一個 page 被換掉，就是由 page-replacement algorithm 決定，不同演算法會有不同結果，但共同目標都是希望所造成的 page fault 最小。&lt;/p&gt;
&lt;h3 id=&#34;first-in-first-out-algorithm-fifo&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#first-in-first-out-algorithm-fifo&#34;&gt;#&lt;/a&gt; First In First Out Algorithm (FIFO)&lt;/h3&gt;
&lt;p&gt;我們使用一個 reference string 來模擬，reference string 就是一個紀錄哪一個 page (編號) 被使用的字串，並假設每一個 process 都只有三個 frame 可以用，FIFO 的意思就是先進來的先出去，最早進到 frame 的 page 最先出去，我們以下圖來說明，假設 reference string 是&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mn&gt;7&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;7,0,1,2,0,3
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8388800000000001em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;那對應到的 page frame 狀態就會長這樣&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/8bBFgL8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;造成 5 個 page fault ，事實上使用 FIFO 演算法還會造成 Belady&#39;s Anomaly, 再給予更多 page frame 的狀態下反而可能造成更多 page fault&lt;/p&gt;
&lt;h3 id=&#34;optimal-algorithm&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#optimal-algorithm&#34;&gt;#&lt;/a&gt; Optimal Algorithm&lt;/h3&gt;
&lt;p&gt;optimal 是最佳的，但實際上我們無法做出最佳的演算法，所以它是一個標準，當我們想要評估一個演算法的好壞時，就拿他跟最佳的演算法比。optimal alogorithm 是置換掉未來最晚被使用到的 page ，舉例來說&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mn&gt;7&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;7,0,1,2,0,3,0,4,2,3,0,3,2,1
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8388800000000001em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.16666666666666666em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;使用 FIFO 在 4 的這個位置，frame 狀態是 (4,3,0)，把 2 換掉，但 optimal 卻是 (2,4,3) 把零換掉，因為零相比 2、3 會更晚才使用到。 optimal 是察看未來的情況做決定，但我們實際上無法預知未來，所以才說 optimal 是做不到的。&lt;/p&gt;
&lt;h3 id=&#34;least-recently-used-lru-algorithm&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#least-recently-used-lru-algorithm&#34;&gt;#&lt;/a&gt; Least Recently Used (LRU) Algorithm&lt;/h3&gt;
&lt;p&gt;雖然無法查看未來，但我們可以記錄過去，LRU 就是基於這樣的想法，所以是置換掉過去最長一段時間沒被使用的 page，而 LRU 和 OPT (optimal) 都是沒有 Bleady&#39;s Anomaly ，也就是說給越多 page frame 越不容易產生 page fault。&lt;br /&gt;
那要如何實作 LRU 呢？這裡提供兩個想法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Counter implementation&lt;/strong&gt;&lt;br /&gt;
 每一個 page 都配有一個 clock ，記錄他被 reference 的時間，然後把這個時間複製到 counter ，當要置換時就挑選時間最小的。這樣有一個缺點就是每次置換時都必須搜尋整個 table ，有點浪費時間&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stack implementation&lt;/strong&gt;&lt;br /&gt;
 另一個方法是使用類似 stack 的資料結構，但和 stack 有點不同，這個方法是指 process 配有一個 stack ，當該 page 被 reference 時，就移到 stack 的 top ， 要置換時則選擇 stack 最底部的 page&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lru-approximation-algorithm&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#lru-approximation-algorithm&#34;&gt;#&lt;/a&gt; LRU Approximation Algorithm&lt;/h3&gt;
&lt;p&gt;因為 LRU 需要特別的硬體支援，速度還是偏慢，所以誘發產出了其他方法，希望效果能盡量接近 LRU&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;reference bit&lt;/strong&gt;&lt;br /&gt;
reference bit 是記錄這個 page 近期也沒有被用到，因此他的值會定時檢查，當需要置換時就優先選擇 reference bit 為 0 的 page，然而我們並不能從 reference 的值得知 page 被 reference 的順序&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Second Chance Algorithm&lt;/strong&gt;&lt;br /&gt;
 這是基於 FIFO 的演算法，不過多了 reference bit 的幫忙，每次要置換時，如果現在輪到的那一個 (最早進來的那一個) 的 reference bit 為 0，那很好直接至換掉他，若他為 1 ，就把它改成 0 ，然後置換掉下一個 (第二早進來的)，這個演算法還有另一種改良，就是除了配有 reference bit 以外，還配有 modify bit 紀錄該 page 是否被修改過，置換時應優先考慮 reference bit 和 modify bit 皆為 0 (最近沒被使用也沒被修改) 的 page 。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;小節&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#小節&#34;&gt;#&lt;/a&gt; 小節&lt;/h3&gt;
&lt;p&gt;以上就是本篇文的內容，更多關於 Allocation of frame 的內容在下篇喔！祝大家閱讀愉快！&lt;/p&gt;
</content>
        <category term="OS" />
        <category term="Memory" />
        <updated>2022-05-29T01:14:45.517Z</updated>
    </entry>
    <entry>
        <id>https://lu1hoao.github.io/2022/05/27/os/os-10/</id>
        <title>Virtual Memory (上)</title>
        <link rel="alternate" href="https://lu1hoao.github.io/2022/05/27/os/os-10/"/>
        <content type="html">&lt;h3 id=&#34;概要&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#概要&#34;&gt;#&lt;/a&gt; 概要&lt;/h3&gt;
&lt;p&gt;本篇文章主要講述 Virtual memory 的管理，討論放在 Virtual memory 的資料如何被搬運至 main memory ，再拿取過程中會碰到甚麼問題又該如何解決，簡而言之就是討論 demand paging 。&lt;/p&gt;
&lt;h3 id=&#34;背景&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#背景&#34;&gt;#&lt;/a&gt; 背景&lt;/h3&gt;
&lt;p&gt;所謂的 virtual memory 指的是 disk ，當一個程式被執行時，他所用到的 data 都應被放在 main memory 中，可是某些程式很大，如果要把整個程式放到 memory 很佔空間，在做 context switch 時也很花時間。因此產生了 virtual memory 的想法，把程式分成很多個 page ，把這些 page 先存在 disk ，需要用他時再把單一個 page 從 disk 搬到 memory 中。&lt;br /&gt;
我們可以用下圖來理解&lt;br /&gt;
&lt;img data-src=&#34;https://i.imgur.com/5HPOkzv.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;電腦轉換步驟如下&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CPU 把 logical arddress 傳給 MMU&lt;/li&gt;
&lt;li&gt;MMU 去該 process 的 page table 找相對應的 frame number (page table 在 memory 中)&lt;/li&gt;
&lt;li&gt;發現在 page table 中該 page 的 valid bit 為零，表示該 page 的資訊還沒被放入 memory&lt;/li&gt;
&lt;li&gt;page table 中有一個指標指到 disk 中該 page 的位置&lt;/li&gt;
&lt;li&gt;到 disk 去把他載入&lt;/li&gt;
&lt;li&gt;CPU 開始執行&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在程式開始執行的那一刻，PCB 已建好，但所有的 page 都還未放入 memory ，直到 CPU 要執行發現 哇！怎麼都沒東西，這時候再去 disk 拿，而這個現象稱為 &lt;strong&gt;page fault&lt;/strong&gt; 拿完之後再回來跟 CPU 說我好了，你可以繼續執行了。&lt;br /&gt;
可以這麼做的原因是因為我們可以把程式分成很多部分，不同部分之間若關聯性不大，那在執行時有沒有把全部都放到 memory 就不重要，稱為程式的 &lt;strong&gt;locality of reference&lt;/strong&gt;。但如果寫程式時規劃得不太好，把彼此有關聯的程式寫在相距很遠的地方，導致他們無法儲存在同一個 page ，執行時產生很多 page fault，我們就稱為 &lt;strong&gt;thrashing&lt;/strong&gt;&lt;br /&gt;
 所以 virtual mamory 的優點有以下幾個&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;program 大小不受記憶體大小限制&lt;/li&gt;
&lt;li&gt;更多的 program 可以同時放到記憶體內 (因為每個 program 佔的空間變小)&lt;/li&gt;
&lt;li&gt;CPU 使用率、產能、回應時間都變好&lt;/li&gt;
&lt;li&gt;I/O 比較少 (因為部分程式碼產生的 I/O 應該會比全部程式碼產生的 I/O 少)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們把該 program 存在 memory 的部分稱為 resident set ，resident set 大小會影響到可以放幾個 program 在 memory 中。&lt;/p&gt;
&lt;h3 id=&#34;demand-paging&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#demand-paging&#34;&gt;#&lt;/a&gt; Demand Paging&lt;/h3&gt;
&lt;p&gt;上一段解釋了 virtual memory 的觀念後，這一段要來說明更細節的注意事項。在 virtual memory 中，page table 會有一個 valid bit 表示這個 page 的狀態，valid 是 1 表示這個 page 在記憶體中，請到相對應的 frame 去取他，若 valid bit 為 0 則表示 page 不在 memory 中或者你存取到別人的位置了，這兩種情況會產生不同的 system call ， OS 也會做相對應的處理。如果是前者，那麼該 process 會被放到 blocking state ，CPU 先去做其他程式，而 OS 也不是透過一般的檔案系統去拿取 disk 中的資料，而是透過 swap 技術，執行這種行為的 swaper 又稱 &lt;strong&gt;Lazy swapper&lt;/strong&gt;、&lt;strong&gt;pager&lt;/strong&gt;，等到所需資料拿到了，CPU 再回頭繼續做這個程式。我們可以用以下圖片說明&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/yVbebtW.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;在開始執行之初，尚未在 memory 放入任何 page ，這種 demand paging 稱為 &lt;strong&gt;pure demand paging&lt;/strong&gt;，在同一個指令中也可能隱含著多個 page fault ，比如指令 move m1 to m2 ，可能 m1 、m2 分屬不同 page 兩個也都不在記憶體中，稱為 multiple page fault，為了避免過多的 page fault (因為到 disk 很花時間) locality reference 就很重要 (把會互相影響的東西放在一起)，從 disk 拿完資料回來後也要記得修改 valid bit&lt;/p&gt;
&lt;h3 id=&#34;performance-of-demand-paging&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#performance-of-demand-paging&#34;&gt;#&lt;/a&gt; Performance of Demand Paging&lt;/h3&gt;
&lt;p&gt;前面一直說 page fault 很花時間，這裡就用實例來看看，假設 memory access time 是 200 ns，有 page fault 時的拿取時間是&lt;br /&gt;
 8000000 ns，有 p 成的機率會產生 page fault ，那麼 effective access time 會變成&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;mn&gt;200&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;mn&gt;8000000&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;(1-p)*200+p*8000000
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;∗&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.72777em;vertical-align:-0.08333em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.6597200000000001em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;∗&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222222222222222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.64444em;vertical-align:0em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;為了避免效率太差，我們應該努力讓 page fault 在 10% 以下。&lt;/p&gt;
&lt;h3 id=&#34;demand-paging-optimuzation&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#demand-paging-optimuzation&#34;&gt;#&lt;/a&gt; Demand Paging Optimuzation&lt;/h3&gt;
&lt;p&gt;要如何增進 demand paging 呢？有以下方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;swap I/O&lt;/strong&gt; ：前面有提到到 disk 拿資料的時候並不是使用 file system，這樣太慢了，我們是在 disk 建 process image 的 copy 然後用指標標明位置再直接到該位置搬進搬出&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;不一定要清空&lt;/strong&gt;： 之後會提到 replacement ，當 process 可用的 frame 不夠時，就要把一些再記憶體的資料清掉，把位置空出來給現在在跑的區段，但如果要清掉的區段都是程式碼，其實不輕質些讓新資料覆蓋也可以，因為 code 不會在執行期間被修改&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Copy-on-Write&lt;/strong&gt;：這是指當 parent fork child 時，不會一開始就真的複製一份，而是先讓這兩個 process 共用同一份，直到其中一個 process 修改內容，才產生複製，給他們一人一份，而這樣的 fork 也稱為 vfork&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;小節&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#小節&#34;&gt;#&lt;/a&gt; 小節&lt;/h3&gt;
&lt;p&gt;本文者要介紹 demand paging 的觀念，其大部基礎都建立在之前講的 paging ，只是 demand  paging 是較省時又省空間的作法，雖然中途會遇到一些問題 (像是 page fault)，但工程師也總能找到相對應的解法，下一節會在講述 demand paging 中的其他細節，祝大家閱讀愉快&lt;/p&gt;
</content>
        <category term="OS" />
        <category term="Memory" />
        <updated>2022-05-27T13:23:28.000Z</updated>
    </entry>
    <entry>
        <id>https://lu1hoao.github.io/2022/05/12/os/os-9/</id>
        <title>Main Memory (下)</title>
        <link rel="alternate" href="https://lu1hoao.github.io/2022/05/12/os/os-9/"/>
        <content type="html">&lt;h3 id=&#34;概要&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#概要&#34;&gt;#&lt;/a&gt; 概要&lt;/h3&gt;
&lt;p&gt;本篇文主要講述 page table 和更多 paging 細節，並對整個 main maemory 做回顧，強烈建議搭配上篇一同觀看&lt;/p&gt;
&lt;h3 id=&#34;implementation-of-page-table&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#implementation-of-page-table&#34;&gt;#&lt;/a&gt; Implementation of Page Table&lt;/h3&gt;
&lt;p&gt;依照上篇提過的 page 方法，我們發現從 page 轉到 frame 需要一個 page table ，而這個 page table 就存在 memory 裡，然而問題來了，我們把資料放進 memory 得過程竟然要存取兩次 memory (一次到 page pagetable 一次到 frame) 這樣也太沒效率了吧！因此我們把 page table 放在一個類似 cache 的硬體，稱作 translation look-aside buffers (TLBs)，如果我們要找的 page 沒出現在 TLB ，這時候稱為 miss ，我們必須到主記憶體去把他的轉換資料找出來並放到 TLB 內，但有了 TLB 這個硬體可以大幅幫助我們提升效率&lt;br /&gt;
加了 TLB 的 address transfer 如下圖&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/NZVxgy8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;effevtive-access-time&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#effevtive-access-time&#34;&gt;#&lt;/a&gt; Effevtive Access Time&lt;/h3&gt;
&lt;p&gt;雖然字面上說增加 TLB 可以提高效率，但還是很沒有實感，那我們就來看看一個例子吧：&lt;br /&gt;
假設 TLB 的存取速度是 20ns ，記憶體的存取速度是 100ns ，有百分之八十的 page 在 TLB 當中就可以取得轉換資訊，那麼平均存取時間就是&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/XKke5l4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;意義是有百分之八十的 page 存取一次 TLB 存取一次 memory ，百分之二十的 page ，存取一次 TLB 沒找到，又再去 page table 找 (存取第一次記憶體) 找到 fram number 後又存取第二次記憶體&lt;br /&gt;
因此若有越高的比率可以在 TLB 就找到資訊，存取速度就會越快&lt;/p&gt;
&lt;h3 id=&#34;memory-protection&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#memory-protection&#34;&gt;#&lt;/a&gt; Memory Protection&lt;/h3&gt;
&lt;p&gt;Page table 除了給予 page 對應到 frame 的位置資訊，也會有一些 bit 記錄這些 page 的其他資訊，像是 valid-invalid bit，因為同一時刻 page table 內可能會有多個 process 的資訊，要避免存取到不是自己的 page ，又或者紀錄這個 page 是否被更動過。對於某些共用部分 code 的 process 而言，我們把這些 shared code 稱為 reentrant，含有這些 code 的 page 可能就會常駐在 TLB 中，一般而言，每次 context switch ，TLB 和 page table 也要被更新&lt;/p&gt;
&lt;h3 id=&#34;structure-of-page-table&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#structure-of-page-table&#34;&gt;#&lt;/a&gt; Structure of page table&lt;/h3&gt;
&lt;p&gt;前面提過 page table 的大小和 page size 有關，假設今天有個 process 的資訊量是 2 的 32 次方，而 page size 是 4KB (2 的 12 次方)，所以這個 process 會用掉 1M ( 2 的 20 次方 ) 個 page，換句話說會有 1M 個 page 地址，假設每個地址需要 4 byte 空間，1M 個地址就會佔去 4M ，佔據記憶體 4M 的空間實在太大了，更何況我們不一定會真正利用到 page table 中的每項資訊，因此如何使放在記憶體當中的資訊不要那麼多，就發展出了以下三種作法&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hierarchical Paging&lt;/li&gt;
&lt;li&gt;Hashed Page Tables&lt;/li&gt;
&lt;li&gt;Inverted Page Tables&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中，Hierarchical Paging 又被稱為 multi-level paging 或 Two-level paging 或 forward-mapped paging ，是實務上最常見的方法&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical Paging&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;是把 page table 在做分割，假設現在圖書館有 1000 本書，我們分成 100 個書架，每個書架有 10 本書，要找一本書的時候就先看他在哪一個書架再去該書架找 (這是原本的 page) 現在又把這 100 個書架分成 10 區，每區有 10 個書架，要找一本書的時候先看他在哪一區，再看他在該區的哪一個書架，最後再到該書架的 10 本書中去找，後者就是 Two-level paging&lt;/p&gt;
&lt;p&gt;原本的 logical address 包含兩個部分，一個是 page number ，一個是 offset ，page number 表示該 page 在 page table 的 index，現在我們把 page number 切成兩個部分，一個表示他對應到哪一個 page table  (又稱 outer page)，一個表示他在該 page table 中的 index (又稱 inner page)。&lt;/p&gt;
&lt;p&gt;我們把圖書館的例子用圖片說明，單純的 page 收到以下訊號&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/kb8lRiZ.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;代表第 83 個書架中的第六本書，而這個圖書館必須在門口張貼一張表，表上有 100 個書架的位置&lt;/p&gt;
&lt;p&gt;two level paging 收到這樣的訊號則會做以下解讀&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/sglq3Z8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;代表第 8 區、第 3 個書架、第 6 本書，而這個圖書館必須張貼一張表，表上有 10 個區域的位置，每個區域入口處也要有屬於該區 10 個書架的位置。&lt;/p&gt;
&lt;p&gt;對記憶體而言 (相當於對圖書館而言) 他需要紀錄的東西從 100 個書架的位址縮小成 10 個區域的位置，減少了很大的負擔。對 CPU 而言 (相當於要找書的人而言)，也不需要修改自己表示資訊的方式 (address 長度不變)，只要換個角度看待資訊就好了。在主記憶體當中只需要存放一個 page table (即圖書館門口的區域位置表)，對每一個 page table 而言，專屬於他們的第二層 page table (相當於各區域門口的書架位址) 放在 disk 即可，需要的時候再去拿，而拿取的技術可以使用前一篇文章提到的 memory image&lt;br /&gt;
 在 two level paging 中會收到兩個位址資訊，其中第一個位址資訊又會成為第二個位址資訊的查詢基礎，有點指來指去的概念。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hashed Page Table&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;顧名思義就是利用雜湊函數對資料作處理，在主記憶體當中存放雜湊表，假設收到以下資訊&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/mPu26jr.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;我們先把 83 mod 7 ，發現餘 6 ，於是找到第六項在去做更進一步處理，看是利用 linklist 或是第二個 page table 還是怎樣都可以，但主記憶體當中只需要存取一個有 7 個項目的雜湊表 (餘數從 0 到 6)，在做雜湊表的時候我們都常會假設資訊是 sparse 的，意思是平均分散的，這樣可以避免 link list 過長。&lt;/p&gt;
&lt;h3 id=&#34;intel-32&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#intel-32&#34;&gt;#&lt;/a&gt; Intel 32&lt;/h3&gt;
&lt;p&gt;在實務上也不是只有利用一種方法做 virtual address 的轉換， Intel 32 就是結合 segmentation 和 paging 的例子，這樣可以結合兩者的優點， segmentation 比較符合人類的分法， 把同樣性質的資料放在一起，paging 則是可以避免 external fragmentation ，所以在 Intel 32 是這樣做的，在 logical address 階段，會得到 segment 資訊和 offset，segmet 資訊稱為  selector，是一個指標，然後在到 descriptor table 中找到他的 base 和 limit ，把 offset 加上 base 之後得到 linear address ，linear assdess 再透過兩次 paging 得到 physical address ，以圖片說明下&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/lOacBea.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;以上就是記憶體的小小小科普，祝大家閱讀愉快&lt;/p&gt;
</content>
        <category term="OS" />
        <category term="Memory" />
        <updated>2022-05-12T13:23:28.000Z</updated>
    </entry>
    <entry>
        <id>https://lu1hoao.github.io/2022/05/11/os/os-8/</id>
        <title>Main Memory (上)</title>
        <link rel="alternate" href="https://lu1hoao.github.io/2022/05/11/os/os-8/"/>
        <content type="html">&lt;h3 id=&#34;概要&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#概要&#34;&gt;#&lt;/a&gt; 概要&lt;/h3&gt;
&lt;p&gt;本文主要講述 Memory 的管理，從背景、 Contiguous Memory Allocation 講到 Segmentation、Paging，對 multiprogramming 的系統而言，記憶體管理很重要，他也會大大影響到執行速度&lt;/p&gt;
&lt;h3 id=&#34;背景&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#背景&#34;&gt;#&lt;/a&gt; 背景&lt;/h3&gt;
&lt;p&gt;我們寫的程式要被執行，必須先被載入到主記憶體當中，CPU 再從 Memory (含 cache) 或 register 去讀取資訊並執行，然而 CPU 看到的這些指令與變數位址並不代表他們真正在記憶體當中的位置，舉例來說，CPU 看到「請執行第十行的指令」這個敘述不表示第十行指令的位址真的在記憶體當中的第十行， 10 這個數字是相對位址，相當於這個程式的第十行，而這個程式的第十行被儲存在記憶體的哪個位置呢？我們需要透過 Memory Management Unit ( MMU ) 搭配 Translation lookaside buffer 來做轉換 ( TLB )，示意圖如下&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/niAzWW5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Memory Management Unit&lt;/strong&gt; (MMU) : 把虛擬地址轉成真實地址的硬體&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Translation Lookaside Buffer&lt;/strong&gt; (TLB): 告訴 MMU 怎麼轉的表 ( a cache for the MMU&#39;s virtual-to-physical translation table )&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;base-and-limit-registers&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#base-and-limit-registers&#34;&gt;#&lt;/a&gt; Base and Limit Registers&lt;/h3&gt;
&lt;p&gt;我們先來看一下簡單的 MMU 轉換例子，假設系統會提供一個 base register ，表示這個程式開端所在的記憶體位址 (真實位址)，那這個程式的每一個指令或變數的真實位址就是他們的相對位址加上這個 base register，這個 base register 又稱為 relocation register，所以可以得到&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;virtual address + relocation register = physical address&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;今天執行程式的 relocation register 和明天執行程式的 relocation register 可能不一樣，因為記憶體空間配置的情形有所差異，但如果程式碼沒有修改，今天和明天的 virtual address 應該是相同的&lt;br /&gt;
大部分時候， complier 會提供 limit register 表示這個程式最大可存取的空間，供系統去做檢查，如果發現這個程式有某個指令或變數位址超過了 relocation register + limit register 的值，我們就可以發覺這個程式應該是有誤的，他會侵犯到別人的空間，以圖片說明：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/jn5GWNf.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;那我們是甚麼時候得到相對位址甚麼時候得到絕對位址的呢？&lt;br /&gt;
這時候就要先來看看程式從寫好到被執行經過了哪些步驟&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;complier&lt;/li&gt;
&lt;li&gt;linker &amp;amp; loader&lt;/li&gt;
&lt;li&gt;execution&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在上面三步中我們是在最後一部才得到真實位址，前面兩部都只是得到相對位址，這裡也要注意所謂的程式起始位置，對不同型態資料來說就會有不同的基準值喔，以下方程式碼說明&lt;/p&gt;
&lt;figure class=&#34;highlight c&#34;&gt;&lt;figcaption data-lang=&#34;c&#34;&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td data-num=&#34;1&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;JUMP X&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;2&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;ADD #&lt;span class=&#34;token number&#34;&gt;4&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td data-num=&#34;3&#34;&gt;&lt;/td&gt;&lt;td&gt;&lt;pre&gt;LOAD Y&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;X 是指第幾行程式碼， Y 則是一個變數，他們在不同的 segment&lt;br /&gt;
 基準位址就不一樣，在 segmentation 中會有更進一步的說明&lt;/p&gt;
&lt;h3 id=&#34;swapping&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#swapping&#34;&gt;#&lt;/a&gt; Swapping&lt;/h3&gt;
&lt;p&gt;swapping 中文是交換的意思，在這裡是指當記憶體位置不足又想跑一個大程式時，我們會把優先權比較低的程式踢去 disk (Backing store) ，讓比較高優先權體積又比較大的程式先跑，這種情況其實很少發生，因為這是下下策，工程師應概要設法用比較好的記憶體管理演算法讓空間使用率最佳化。但不幸出現這種事時，我們會把低優先權程式在記憶體中的狀態原封不動地搬到 disk ，稱為 memory image ，再次啟動低優先權 process 時就不需要再透過檔案系統開啟&lt;/p&gt;
&lt;h3 id=&#34;contiguous-allocation&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#contiguous-allocation&#34;&gt;#&lt;/a&gt; Contiguous Allocation&lt;/h3&gt;
&lt;p&gt;現在我們終於可以來看一下記憶體是如何被使用的了，一般來說記憶體被分為兩大塊 (two partitions) 一塊給 OS ，一塊給我們要跑的程式，在 multiprogramming 系統中，又把放置 user process 的記憶體切成多塊，切法又可分為以下兩種：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fixed Partition&lt;/strong&gt;&lt;br /&gt;
 顧名思義，這裡的記憶體被切成等大的片段，每個片段放置一個 process，假設現在記憶體當中有 3 個 process ，那我們就說現在 degree 是 3，但是切成等大的片段會造成空間利用率不高，對於那些所需空間小於一個片段的 process 來說，我們多給的片段他也用不到，這種被浪費掉的空間稱為 &lt;strong&gt;Interal Fragmentation&lt;/strong&gt;，對於大小超過一個片段的 process 他也放不進去無法被執行，因此這個做法還有很多變形，像是執行一個大 process 時，不需要把整個 process 都放到記憶體，只需要放正在執行的片段就可以了&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Variable-Partition&lt;/strong&gt;&lt;br /&gt;
Variable-Partition 就是把記憶體切成大小不一的片段，以符合每個 process 不同的空間需求&lt;br /&gt;
&lt;strong&gt; (1) Buddy&#39;s System：&lt;/strong&gt;&lt;br /&gt;
Buddy&#39;s system 是指讓每塊記憶體片段都是 2 的指數次方大小，比如 2、4、8、16、64，假設今天來了一個 35 大小的 process 他就選擇 64 這個記憶體片段，但假如今天 64 大小的都用完了怎麼辦呢？就選擇 128 大小的，但把 128 切成兩塊 64，一塊給 35 ，剩下的一塊就待命&lt;br /&gt;
&lt;strong&gt; (2) 一般的 variable partition ：&lt;/strong&gt;&lt;br /&gt;
就是依照 process 大小給與剛好空的空間&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;當 process 離開記憶體後他原本佔據的空間就會空出來，稱為 &lt;strong&gt;hole&lt;/strong&gt; (也可以說，沒被 process 佔據的空間都視為 hole)，當新的 process 要進來記憶體時，就從這些 hole 挑選一個適合大小給 process，怎麼挑呢？又可以分為以下幾種&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;First-fit&lt;/strong&gt;：找到第一個是大小大於或等於 proess 的 hole 就結束&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Best-fit&lt;/strong&gt;：找到大小大於或等於 process 的 hole，且這個 hole 是所有可供 process 運用的 hole 當中最小的&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Next-fit&lt;/strong&gt;：從上一個找到的 hole 作為起點，當找到第一個大小大於或等於 process 的 hole 之後就結束&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以圖片說明，假設灰色是以被占據的記憶體空間，白色是 hole，現在來了一個需要 16 大小的 proess，那根據不同的選法就會有不一樣的結果&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/BxorVjG.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;一般來說， first-fit 會讓上面的記憶體更常被選到，經常使用意味著更容易壞掉， best-fit 則需要全部搜尋一遍有點浪費時間，next-fit 算是比較折衷的方法但是也可能會選到 worst fit (適合 process 的 hole 中，最大的那一個)&lt;/p&gt;
&lt;p&gt;如果今天有一個大小為 3 的洞，和一個大小為 5 的洞，來了一個大小為 7 的 process 要怎麼辦呢？ 如果系統沒辦法透過調整記憶體中 process 的位置來解決這個問題，我們就稱這兩個洞是 &lt;strong&gt;External Fragmentation&lt;/strong&gt;，雖然是可運用的空間卻無法真正被利用。為了解決這個問題，我們需要 &lt;strong&gt;Compaction&lt;/strong&gt; ，調整記憶體中 process 的位置，讓這兩個洞合併成一個大洞供 process 使用，調整 process 位置就需要最一開始提到的 relocation code 才有辦法&lt;/p&gt;
&lt;h3 id=&#34;segmentation&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#segmentation&#34;&gt;#&lt;/a&gt; Segmentation&lt;/h3&gt;
&lt;p&gt;我們的程式是由不同的 segment 組成的，比如變數存在 data segment，程式碼存在 code segment，當我們要找出這些變數或程式碼的真實位置時，就需要取他們的虛擬位置加上 segment 資訊。&lt;br /&gt;
一般來說，logical address (virtual address) 是由兩個數字組成，一個表示他在哪一個 segment (他們的型態) ，通常為 segment-table base register (STBR，指向該 segment table 在記憶體中的位址) 和他們的 offset (位移，相當於對該 segment 起點的位移)，我們透過 segment table 可以得到 base 和 limit 資訊，進而得到 physical address ，以圖片說明&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/6BJyXtk.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;paging&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#paging&#34;&gt;#&lt;/a&gt; Paging&lt;/h3&gt;
&lt;p&gt;Paging ，是把 process 分成大小相同的區塊稱為 page (和 segment 不同喔， 每塊 segment 大小可能不同)，然後在真實記憶體當中，我們也切成大小相同的好幾塊，稱為 frame ，一塊 frame 的體積和一塊 page 的體積大小相同，透過 page table ，把 page 資訊放到 frame 當中。這樣的做法可以避免 external fragmentation，但依然會有 internal fragmentation 以下方簡圖說明&lt;br /&gt;
 CPU 得到的 logical address (virtual address)，包含兩個數字，一個是 &lt;strong&gt;virtual page number&lt;/strong&gt; (VPN)，是一個 index ，表示這個 page 在 page table 中的位置，和一個 Page offse 該資料相對於這個 page 的起始位址位移多少，在 page table 中則會記載每一個 page table 對應到真實記憶體當中的哪一個 frame&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://i.imgur.com/Zd8yrER.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;這裡要注意從 page 對應到 memory 不一定要依照 page 的次序，舉例來說第一塊 page 不一定要對應到第一塊 frame，也可以是第五塊，因為每一塊 frame 大小都相同，所以對應到哪一塊其實沒差，隱含著一個重要訊息，&lt;strong&gt;在真實記憶體當中，一個 process 存放的空間可以是不連續的&lt;/strong&gt;，事實上 page 分類在 disk 就已經完成，後面會更詳細解說。 我們用下面例子說明空間使用情況&lt;br /&gt;
假設一個 page 是 2048 bytes，有一個 72766 bytes 的 process ，這樣他需要 36 個 pages ，但最後一個 page 沒有裝滿，會有 962 bytes 的 internal fragmentation&lt;br /&gt;
 如果一個 page 容量越大，就可能會造成越多 internal fragmentation ，如果單一 page 容量很小又會造成 page table 很大，因為他要存放這些 page 的位址，不過依電腦趨勢而言， page 的尺寸是越做越大&lt;/p&gt;
&lt;p&gt;原本想要一篇打完的，但內容好多，剩下的留到下篇，祝大家閱讀愉快&lt;/p&gt;
</content>
        <category term="OS" />
        <category term="Memory" />
        <updated>2022-05-11T13:23:28.000Z</updated>
    </entry>
</feed>
